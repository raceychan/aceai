{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# Multi-step Logistics Scenario\n",
    "This notebook wires up a shipping-focused tool stack so the agent must combine several tool calls to answer a single request.\n",
    "Run the cells sequentially and finish by executing the scenario cell to watch the agent plan a shipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated\n",
    "\n",
    "from httpx import AsyncClient\n",
    "from loguru import logger\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from aceai.agent import AgentBase, ToolExecutor\n",
    "from aceai.llm import LLMService\n",
    "from aceai.llm.openai import OpenAI\n",
    "from aceai.tools import spec, tool, Tool\n",
    "from ididi import Graph, use\n",
    "\n",
    "values = dotenv_values(\".env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAREHOUSE_ORDERS = {\n",
    "    \"ORD-200\": {\n",
    "        \"destination\": \"Denver, CO\",\n",
    "        \"priority\": \"express\",\n",
    "        \"notes\": \"Helios Labs needs hardware before the Wednesday stand-up.\",\n",
    "        \"items\": [\n",
    "            {\"sku\": \"sensor-kit\", \"quantity\": 45},\n",
    "            {\"sku\": \"control-module\", \"quantity\": 30},\n",
    "            {\"sku\": \"battery-pack\", \"quantity\": 60},\n",
    "        ],\n",
    "    },\n",
    "    \"ORD-207\": {\n",
    "        \"destination\": \"Austin, TX\",\n",
    "        \"priority\": \"standard\",\n",
    "        \"notes\": \"Stocking field pod replacements.\",\n",
    "        \"items\": [\n",
    "            {\"sku\": \"telemetry-node\", \"quantity\": 22},\n",
    "            {\"sku\": \"cooling-shroud\", \"quantity\": 18},\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "SKU_WEIGHTS = {\n",
    "    \"sensor-kit\": 0.85,\n",
    "    \"control-module\": 1.4,\n",
    "    \"battery-pack\": 0.65,\n",
    "    \"telemetry-node\": 1.1,\n",
    "    \"cooling-shroud\": 2.2,\n",
    "}\n",
    "\n",
    "SHIPPING_RATES = {\n",
    "    \"standard\": {\"base\": 48.0, \"per_kg\": 1.35, \"eta_days\": 5},\n",
    "    \"express\": {\"base\": 92.0, \"per_kg\": 1.95, \"eta_days\": 2},\n",
    "}\n",
    "\n",
    "@tool\n",
    "def lookup_order(\n",
    "    order_id: Annotated[str, spec(description=\"Order identifier such as ORD-200.\")]\n",
    ") -> str:\n",
    "    \"\"\"Return line items, destination, and priority for a warehouse order.\"\"\"\n",
    "    order = WAREHOUSE_ORDERS.get(order_id.upper())\n",
    "    if not order:\n",
    "        raise ValueError(f\"Unknown order {order_id}\")\n",
    "    return json.dumps(order)\n",
    "\n",
    "@tool\n",
    "def get_sku_weight(\n",
    "    sku: Annotated[str, spec(description=\"Catalog SKU to pull the per-unit weight for.\")]\n",
    ") -> str:\n",
    "    \"\"\"Return the per-unit weight for a SKU in kilograms.\"\"\"\n",
    "    key = sku.lower()\n",
    "    if key not in SKU_WEIGHTS:\n",
    "        raise ValueError(f\"Unknown SKU {sku}\")\n",
    "    return json.dumps({\"sku\": key, \"weight_kg\": SKU_WEIGHTS[key]})\n",
    "\n",
    "@tool\n",
    "def estimate_shipping_cost(\n",
    "    weight_kg: Annotated[float, spec(description=\"Total shipment mass in kilograms.\")],\n",
    "    method: Annotated[str, spec(description=\"Shipping tier to price (standard or express).\")],\n",
    ") -> str:\n",
    "    \"\"\"Quote the shipping cost given a total weight and service tier.\"\"\"\n",
    "    method_key = method.strip().lower()\n",
    "    if method_key not in SHIPPING_RATES:\n",
    "        raise ValueError(f\"Unsupported shipping method {method}\")\n",
    "    rates = SHIPPING_RATES[method_key]\n",
    "    cost = rates[\"base\"] + weight_kg * rates[\"per_kg\"]\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"method\": method_key,\n",
    "            \"weight_kg\": round(weight_kg, 2),\n",
    "            \"cost_usd\": round(cost, 2),\n",
    "            \"eta_days\": rates[\"eta_days\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "OPEN_METEO_GEOCODE = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
    "OPEN_METEO_FORECAST = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "async def build_async_http_client() -> AsyncClient:\n",
    "    return AsyncClient(timeout=20.0)\n",
    "\n",
    "@tool\n",
    "async def fetch_weather_window(\n",
    "    city: Annotated[str, spec(description=\"Destination city to inspect\")],\n",
    "    client: Annotated[AsyncClient, use(build_async_http_client, reuse=False)],\n",
    ") -> str:\n",
    "    \"\"\"Fetch a quick temperature and precipitation outlook for the next 24 hours.\"\"\"\n",
    "    try:\n",
    "        geo_resp = await client.get(\n",
    "            OPEN_METEO_GEOCODE,\n",
    "            params={\"name\": city, \"count\": 1, \"language\": \"en\", \"format\": \"json\"},\n",
    "            timeout=15.0,\n",
    "        )\n",
    "        geo_resp.raise_for_status()\n",
    "        geo_payload = geo_resp.json()\n",
    "        results = geo_payload.get(\"results\") or []\n",
    "        if not results:\n",
    "            raise ValueError(f\"No coordinates found for {city}\")\n",
    "        location = results[0]\n",
    "        lat = location[\"latitude\"]\n",
    "        lon = location[\"longitude\"]\n",
    "\n",
    "        forecast_resp = await client.get(\n",
    "            OPEN_METEO_FORECAST,\n",
    "            params={\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"hourly\": \"temperature_2m,precipitation_probability\",\n",
    "                \"forecast_days\": 1,\n",
    "                \"timezone\": \"auto\",\n",
    "            },\n",
    "            timeout=15.0,\n",
    "        )\n",
    "        forecast_resp.raise_for_status()\n",
    "        forecast = forecast_resp.json()[\"hourly\"]\n",
    "        temps = forecast[\"temperature_2m\"]\n",
    "        precip = forecast[\"precipitation_probability\"]\n",
    "        avg_temp = sum(temps) / len(temps)\n",
    "        max_precip = max(precip)\n",
    "\n",
    "        summary = {\n",
    "            \"city\": city,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"avg_temp_c\": round(avg_temp, 1),\n",
    "            \"max_precip_probability\": int(max_precip),\n",
    "            \"source\": \"open-meteo\",\n",
    "        }\n",
    "        return json.dumps(summary)\n",
    "    finally:\n",
    "        await client.aclose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "logging-executor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "from aceai.llm.interface import LLMToolCall\n",
    "\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sys.stdout,\n",
    "    format=\"{time:YYYY-MM-DD HH:mm:ss.SSS} | {level:<7} | {message}\",\n",
    "    colorize=False,\n",
    ")\n",
    "\n",
    "class LoggingToolExecutor(ToolExecutor):\n",
    "    async def execute_tool(self, tool_call: LLMToolCall) -> str:\n",
    "        call_id = tool_call.call_id or tool_call.id or \"n/a\"\n",
    "        logger.info(\n",
    "            \"Tool {name} starting (call_id={call_id})\",\n",
    "            name=tool_call.name,\n",
    "            call_id=call_id,\n",
    "        )\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            payload = await super().execute_tool(tool_call)\n",
    "        except Exception:\n",
    "            duration = time.perf_counter() - start\n",
    "            logger.exception(\n",
    "                \"Tool {name} failed after {duration:.2f}s\",\n",
    "                name=tool_call.name,\n",
    "                duration=duration,\n",
    "            )\n",
    "            raise\n",
    "        duration = time.perf_counter() - start\n",
    "        logger.success(\n",
    "            \"Tool {name} finished in {duration:.2f}s\",\n",
    "            name=tool_call.name,\n",
    "            duration=duration,\n",
    "        )\n",
    "        return payload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "build-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(prompt: str, max_turns: int, tools: list[Tool]) -> AgentBase:\n",
    "    openai_llm = OpenAI(\n",
    "        api_key=values[\"OPENAI_API_KEY\"],\n",
    "        default_model=\"gpt-4\",\n",
    "        default_stream_model=\"gpt-4-turbo\",\n",
    "    )\n",
    "    graph = Graph()\n",
    "\n",
    "    llm_service = LLMService(\n",
    "        providers=[openai_llm],\n",
    "        timeout_seconds=120,\n",
    "    )\n",
    "    executor = LoggingToolExecutor(\n",
    "        tools=tools,\n",
    "        graph=graph,\n",
    "    )\n",
    "\n",
    "\n",
    "    return AgentBase(\n",
    "        prompt=prompt,\n",
    "        default_model=\"gpt-4\",\n",
    "        llm_service=llm_service,\n",
    "        executor=executor,\n",
    "        max_turns=max_turns,\n",
    "    )\n",
    "\n",
    "agent = build_agent(prompt=(\n",
    "        \"You are the logistics coordinator for AceAI. \"\n",
    "        \"Always inspect orders, fetch SKU weights, price shipping strictly through the available tools, \"\n",
    "        \"and incorporate the weather outlook before deciding on a service level.\"\n",
    "    ), max_turns=20, tools=[lookup_order, get_sku_weight, estimate_shipping_cost, fetch_weather_window])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenario-md",
   "metadata": {},
   "source": [
    "## Scenario: plan shipment for ORD-200\n",
    "The following cell asks the agent to pull data for an urgent order, compute the shipment mass, price both service tiers, and consider the destination weather. Expect the agent to call:\n",
    "1. `lookup_order`\n",
    "2. `get_sku_weight` for each SKU\n",
    "3. `estimate_shipping_cost` twice\n",
    "4. `fetch_weather_window` for the destination city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce20f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "run-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 04:04:09.324 | INFO    | Tool lookup_order starting (call_id=call_zkOF8FHIV4hNCN158XZpp3Qw)\n",
      "2025-12-06 04:04:09.325 | SUCCESS | Tool lookup_order finished in 0.00s\n",
      "2025-12-06 04:04:15.081 | INFO    | Tool get_sku_weight starting (call_id=call_hGQ9TB25OVVQnCCQoq3ZInXR)\n",
      "2025-12-06 04:04:15.082 | SUCCESS | Tool get_sku_weight finished in 0.00s\n",
      "2025-12-06 04:04:15.082 | INFO    | Tool get_sku_weight starting (call_id=call_S1GUrXveXMEHWS1PWxSClm40)\n",
      "2025-12-06 04:04:15.083 | SUCCESS | Tool get_sku_weight finished in 0.00s\n",
      "2025-12-06 04:04:15.083 | INFO    | Tool get_sku_weight starting (call_id=call_KNixyvMVnFBNrVkbX5I6Nsip)\n",
      "2025-12-06 04:04:15.084 | SUCCESS | Tool get_sku_weight finished in 0.00s\n",
      "2025-12-06 04:04:17.684 | INFO    | Tool estimate_shipping_cost starting (call_id=call_mMC9cmSagakY2Q7kZwm3AeQM)\n",
      "2025-12-06 04:04:17.684 | SUCCESS | Tool estimate_shipping_cost finished in 0.00s\n",
      "2025-12-06 04:04:20.453 | INFO    | Tool estimate_shipping_cost starting (call_id=call_S1N92G0jVG3pv8ySgPdcFrUy)\n",
      "2025-12-06 04:04:20.454 | SUCCESS | Tool estimate_shipping_cost finished in 0.00s\n",
      "2025-12-06 04:04:22.912 | INFO    | Tool fetch_weather_window starting (call_id=call_Fvr3ABR4jmEXMmqlsb13qase)\n",
      "2025-12-06 04:04:23.423 | ERROR   | Tool fetch_weather_window failed after 0.51s\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/ipykernel/...\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x79221fdb8ae0>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7922221439e0>\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x79221fdbb6a0>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7922067ead50>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7922221439e0>\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x792221356020>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7922067ead50>\n",
      "  File \"/home/raceychan/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/asyncio/base_events.py\", line 640, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x792221357e20>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/home/raceychan/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/asyncio/base_events.py\", line 1992, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x7922214db7e0>\n",
      "    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x79220430b2e0>()>\n",
      "  File \"/home/raceychan/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │            │    │           └ <Handle <_asyncio.TaskStepMethWrapper object at 0x79220430b2e0>()>\n",
      "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
      "    │    │            └ <Handle <_asyncio.TaskStepMethWrapper object at 0x79220430b2e0>()>\n",
      "    │    └ <member '_context' of 'Handle' objects>\n",
      "    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x79220430b2e0>()>\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/tmp/ipykernel_315523/1224521056.py'\n",
      "                       │    │             │        └ [<ast.Assign object at 0x792204bde010>, <ast.Expr object at 0x792204bdd1d0>]\n",
      "                       │    │             └ <ast.Module object at 0x792205e04d10>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x7922207dfc40>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79221fdea5a0>\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ True\n",
      "             │    │        │     └ <ExecutionResult object at 792204aedfa0, execution_count=5 error_before_exec=None error_in_exec=None info=<ExecutionInfo obje...\n",
      "             │    │        └ <code object <module> at 0x792204992b30, file \"/tmp/ipykernel_315523/1224521056.py\", line 1>\n",
      "             │    └ <function InteractiveShell.run_code at 0x7922207dfce0>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79221fdea5a0>\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "               │         │    │               │    └ <property object at 0x7922207d4ea0>\n",
      "               │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79221fdea5a0>\n",
      "               │         │    └ <property object at 0x7922207d4f40>\n",
      "               │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79221fdea5a0>\n",
      "               └ <code object <module> at 0x792204992b30, file \"/tmp/ipykernel_315523/1224521056.py\", line 1>\n",
      "\n",
      "  File \"/tmp/ipykernel_315523/1224521056.py\", line 14, in <module>\n",
      "    await agent.handle(multi_step_question)\n",
      "          │     │      └ \"\\nYou are preparing a logistics brief for Helios Labs covering order ORD-200.\\n\\nTasks:\\n1. Call `lookup_order` to restate t...\n",
      "          │     └ <function AgentBase.handle at 0x792204ae6980>\n",
      "          └ <aceai.agent.AgentBase object at 0x792204bd5100>\n",
      "\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/aceai/agent.py\", line 55, in handle\n",
      "    tool_result = await self.executor.execute_tool(call)\n",
      "                        │    │        │            └ LLMToolCall(name='fetch_weather_window', arguments='{\\n  \"city\": \"Denver, CO\"\\n}', type='function', call_id='call_Fvr3ABR4jmE...\n",
      "                        │    │        └ <function LoggingToolExecutor.execute_tool at 0x792205ca0d60>\n",
      "                        │    └ <__main__.LoggingToolExecutor object at 0x792204aecef0>\n",
      "                        └ <aceai.agent.AgentBase object at 0x792204bd5100>\n",
      "\n",
      "> File \"/tmp/ipykernel_315523/1770665084.py\", line 23, in execute_tool\n",
      "    payload = await super().execute_tool(tool_call)\n",
      "                                         └ LLMToolCall(name='fetch_weather_window', arguments='{\\n  \"city\": \"Denver, CO\"\\n}', type='function', call_id='call_Fvr3ABR4jmE...\n",
      "\n",
      "  File \"/home/raceychan/myprojects/pyprojects/aceai/aceai/executor.py\", line 42, in execute_tool\n",
      "    result = await result\n",
      "                   └ <coroutine object fetch_weather_window at 0x79220499fe20>\n",
      "\n",
      "  File \"/tmp/ipykernel_315523/2263703106.py\", line 98, in fetch_weather_window\n",
      "    raise ValueError(f\"No coordinates found for {city}\")\n",
      "                                                 └ 'Denver, CO'\n",
      "\n",
      "ValueError: No coordinates found for Denver, CO\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No coordinates found for Denver, CO",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m multi_step_question = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mYou are preparing a logistics brief for Helios Labs covering order ORD-200.\u001b[39m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[33mPresent the answer as a brief overview paragraph plus bullet points that cover total weight, each quote, the weather takeaway, and the final recommendation.\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent.handle(multi_step_question)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myprojects/pyprojects/aceai/aceai/agent.py:55\u001b[39m, in \u001b[36mAgentBase.handle\u001b[39m\u001b[34m(self, question, model)\u001b[39m\n\u001b[32m     53\u001b[39m messages.append(assistant_msg)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m call \u001b[38;5;129;01min\u001b[39;00m response.tool_calls:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     tool_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.executor.execute_tool(call)\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m call.name == \u001b[33m\"\u001b[39m\u001b[33mfinal_answer\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     57\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tool_result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mLoggingToolExecutor.execute_tool\u001b[39m\u001b[34m(self, tool_call)\u001b[39m\n\u001b[32m     21\u001b[39m start = time.perf_counter()\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     payload = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().execute_tool(tool_call)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     25\u001b[39m     duration = time.perf_counter() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myprojects/pyprojects/aceai/aceai/executor.py:42\u001b[39m, in \u001b[36mToolExecutor.execute_tool\u001b[39m\u001b[34m(self, tool_call)\u001b[39m\n\u001b[32m     40\u001b[39m result = tool(**params, **dep_params)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tool.encode_return(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mfetch_weather_window\u001b[39m\u001b[34m(city, client)\u001b[39m\n\u001b[32m     96\u001b[39m results = geo_payload.get(\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo coordinates found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m location = results[\u001b[32m0\u001b[39m]\n\u001b[32m    100\u001b[39m lat = location[\u001b[33m\"\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: No coordinates found for Denver, CO"
     ]
    }
   ],
   "source": [
    "multi_step_question = \"\"\"\n",
    "You are preparing a logistics brief for Helios Labs covering order ORD-200.\n",
    "\n",
    "Tasks:\n",
    "1. Call `lookup_order` to restate the destination, priority, and every SKU with its quantity.\n",
    "2. Use `get_sku_weight` for each SKU individually so you can calculate the total shipment weight in kilograms.\n",
    "3. Price BOTH `standard` and `express` service levels by calling `estimate_shipping_cost` twice with the total weight.\n",
    "4. Call `fetch_weather_window` for the destination city to understand short-term weather risks that might impact delivery.\n",
    "5. Recommend which service level to book, citing cost, ETA, the customer's stated priority, and the weather outlook.\n",
    "\n",
    "Present the answer as a brief overview paragraph plus bullet points that cover total weight, each quote, the weather takeaway, and the final recommendation.\n",
    "\"\"\"\n",
    "\n",
    "await agent.handle(multi_step_question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aceai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
